{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39595481",
   "metadata": {},
   "source": [
    "<h1><font color=\"purple\">MODÉLISATION DEEP LEARNING</font></h1>\n",
    "<h2><font color = \"navy\">Travail préliminaire</font></h2>\n",
    "<ul><li>Importation des librairies nécessaires.</li><li>Création et exploration du dataframe de travail.</li><li>Création d'un second dataframe (<i>ne sera pas modifié</i>).</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa18c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import Markdown, display\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme({'legend.frameon':True})\n",
    "from tensorflow.keras.layers import Input, Dense \n",
    "from tensorflow.keras.models import Model\n",
    "import itertools \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#pip install --upgrade tensorflow\n",
    "#pip install pydot\n",
    "#pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c250722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\A_DATASCIENCE\\DATASCIENTEST\\FIL_ROUGE\\weatherAUS.csv\")\n",
    "\n",
    "#Création d'un df de secours pour avoir une trace des données brutes.\n",
    "\n",
    "df_saved = pd.read_csv(\"E:\\A_DATASCIENCE\\DATASCIENTEST\\FIL_ROUGE\\weatherAUS.csv\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5711266d",
   "metadata": {},
   "source": [
    "<h2><font color = \"navy\">Préprocessing</font></h2>\n",
    "<ul><li>Regroupement géographique.</li><li>Remplacement des valeurs manquantes.</li><li>Reformation du dataframe de travail</li><li>Création de variables.</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18754b5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In progress: df_Perth2. 6901 nans before cleaning (2.8 %)\n",
      "\tCleaning done: df_Perth2. 432 nans remaining (0.2 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Albany2. 38056 nans before cleaning (15.6 %)\n",
      "\tCleaning done: df_Albany2. 4583 nans remaining (2.0 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Alice2. 7895 nans before cleaning (6.3 %)\n",
      "\tCleaning done: df_Alice2. 381 nans remaining (0.3 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Adelaide2. 11572 nans before cleaning (6.9 %)\n",
      "\tCleaning done: df_Adelaide2. 498 nans remaining (0.3 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Nhil2. 14159 nans before cleaning (6.9 %)\n",
      "\tCleaning done: df_Nhil2. 473 nans remaining (0.2 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Portland2. 12342 nans before cleaning (5.0 %)\n",
      "\tCleaning done: df_Portland2. 780 nans remaining (0.3 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Melbourne2. 20439 nans before cleaning (5.0 %)\n",
      "\tCleaning done: df_Melbourne2. 737 nans remaining (0.2 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Albury2. 11516 nans before cleaning (7.1 %)\n",
      "\tCleaning done: df_Albury2. 723 nans remaining (0.5 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Canberra2. 21556 nans before cleaning (12.3 %)\n",
      "\tCleaning done: df_Canberra2. 1745 nans remaining (1.0 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Sydney2. 44262 nans before cleaning (10.6 %)\n",
      "\tCleaning done: df_Sydney2. 2778 nans remaining (0.7 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Newcastle2. 45155 nans before cleaning (18.5 %)\n",
      "\tCleaning done: df_Newcastle2. 5774 nans remaining (2.6 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Cobar2. 7528 nans before cleaning (4.6 %)\n",
      "\tCleaning done: df_Cobar2. 297 nans remaining (0.2 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Brisbane2. 20407 nans before cleaning (8.2 %)\n",
      "\tCleaning done: df_Brisbane2. 1108 nans remaining (0.5 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Cairns2. 2691 nans before cleaning (1.6 %)\n",
      "\tCleaning done: df_Cairns2. 210 nans remaining (0.1 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Hobart2. 2505 nans before cleaning (2.9 %)\n",
      "\tCleaning done: df_Hobart2. 79 nans remaining (0.1 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_SalmonGums. 18854 nans before cleaning (23.3 %)\n",
      "\tCleaning done: df_SalmonGums. 17795 nans remaining (22.4 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Darwin. 196 nans before cleaning (0.2 %)\n",
      "\tCleaning done: df_Darwin. 76 nans remaining (0.1 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Katherine. 4392 nans before cleaning (10.3 %)\n",
      "\tCleaning done: df_Katherine. 1648 nans remaining (4.0 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_Woomera. 2740 nans before cleaning (3.4 %)\n",
      "\tCleaning done: df_Woomera. 85 nans remaining (0.1 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_MountGinini. 21801 nans before cleaning (26.6 %)\n",
      "\tCleaning done: df_MountGinini. 17342 nans remaining (22.8 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "In progress: df_NorfolkIsland. 1096 nans before cleaning (1.3 %)\n",
      "\tCleaning done: df_NorfolkIsland. 78 nans remaining (0.1 %)\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Cleaning complete.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Il y avait initialement <b>343248 valeurs manquantes</b> dans la base de données (<b>10.3 %</b> des données totales), répartis sur 145460 entrées.\n",
       "Le preprocessing a permis de réduire le nombre de valeurs manquantes à <b>57622</b> : <b>83.2 %</b> des valeurs manquantes initiales ont été remplacés.\n",
       "Après suppression de 4 colonnes comportant trop de valeurs manquantes, et suppression des valeurs manquantes restantes, il reste <b>129127 relevés</b> dans la base.\n",
       "Au total, <b>88.8 %</b> des relevés météorologiques ont été <b>conservés</b>.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Création de Year, Month & Day\n",
    "df[\"Year\"] = df[\"Date\"].apply(lambda x : int(x[:4]))\n",
    "df[\"Month\"] = df[\"Date\"].apply(lambda x : int(x[5:7]))\n",
    "df[\"Day\"] = df[\"Date\"].apply(lambda x : int(x[8:]))\n",
    "\n",
    "#Création du dictionnaire qui contient pour chaque état australier, les stations associées\n",
    "localites = {\"SA\" : [\"Adelaide\", \"MountGambier\", \"Woomera\", \"Nuriootpa\"],\n",
    "            \"WA\" : [\"Perth\", \"Albany\", \"PearceRAAF\", \"PerthAirport\", \"Walpole\", \"SalmonGums\", \"Witchcliffe\"],\n",
    "            \"NSW\" : [\"Canberra\", \"Sydney\", \"Albury\", \"Wollongong\", \"MountGinini\", \"Tuggeranong\", \"Penrith\", \"Newcastle\", \"Cobar\", \"SydneyAirport\", \"BadgerysCreek\", \"WaggaWagga\", \"Moree\", \"Williamtown\", \"CoffsHarbour\", \"NorahHead\", \"Richmond\"],\n",
    "            \"QLD\" : [\"Brisbane\", \"Townsville\", \"Cairns\", \"GoldCoast\"],\n",
    "            \"TAS\" : [\"Hobart\", \"Launceston\"],\n",
    "            \"VIC\" : [\"Melbourne\", \"Bendigo\", \"Ballarat\", \"Dartmoor\", \"Portland\", \"Mildura\", \"MelbourneAirport\", \"Sale\", \"Watsonia\", \"Nhil\"],\n",
    "            \"NT\" : [\"Darwin\", \"AliceSprings\", \"Katherine\", \"Uluru\"],\n",
    "            \"NI\" : [\"NorfolkIsland\"]}\n",
    "\n",
    "#Création de la colonne State\n",
    "df[\"State\"] = df.Location\n",
    "df[\"State\"] = df[\"State\"].replace(to_replace = [\"Adelaide\", \"MountGambier\", \"Woomera\", \"Nuriootpa\"], value = \"SA\")\n",
    "df[\"State\"] = df[\"State\"].replace(to_replace = [\"Perth\", \"Albany\", \"PearceRAAF\", \"PerthAirport\", \"Walpole\", \"SalmonGums\", \"Witchcliffe\"], value = \"WA\")\n",
    "df[\"State\"] = df[\"State\"].replace(to_replace = [\"Canberra\", \"Sydney\", \"Albury\", \"Wollongong\", \"MountGinini\", \"Tuggeranong\", \"Penrith\", \"Newcastle\", \"Cobar\", \"SydneyAirport\", \"BadgerysCreek\", \"WaggaWagga\", \"Moree\", \"Williamtown\", \"CoffsHarbour\", \"NorahHead\", \"Richmond\"], value = \"NSW\")\n",
    "df[\"State\"] = df[\"State\"].replace(to_replace = [\"Brisbane\", \"Townsville\", \"Cairns\", \"GoldCoast\"], value = \"QLD\")\n",
    "df[\"State\"] = df[\"State\"].replace(to_replace = [\"Hobart\", \"Launceston\"], value = \"TAS\")\n",
    "df[\"State\"] = df[\"State\"].replace(to_replace = [\"Melbourne\", \"Bendigo\", \"Ballarat\", \"Dartmoor\", \"Portland\", \"Mildura\", \"MelbourneAirport\", \"Sale\", \"Watsonia\", \"Nhil\"], value = \"VIC\")\n",
    "df[\"State\"] = df[\"State\"].replace(to_replace = [\"Darwin\", \"AliceSprings\", \"Katherine\", \"Uluru\"], value = \"NT\")\n",
    "df[\"State\"] = df[\"State\"].replace(to_replace = [\"NorfolkIsland\"], value = \"NI\")\n",
    "\n",
    "#Création des deux listes nécessaires au remplacement des nans.\n",
    "loclst = []\n",
    "locgroup = [\"NorfolkIsland\", \"Portland\", \"MountGinini\", \"Adelaide\", \"Darwin\", \"MountGambier\", \"GoldCoast\", \"Canberra\", \"Newcastle\", \"Woomera\",\n",
    "           \"Witchcliffe\", \"Moree\", \"Wollongong\", \"Bendigo\", \"Mildura\", \"WaggaWagga\", \"Dartmoor\",\"Hobart\", \"SalmonGums\", \"Williamtown\",\n",
    "            \"Townsville\", \"PerthAirport\", \"Sydney\", \"Perth\", \"Katherine\", \"Albury\", \"Ballarat\", \"MelbourneAirport\",\n",
    "           \"BagerysCreek\", \"Melbourne\", \"Cairns\", \"NorahHead\", \"PearceRAAF\", \"Uluru\", \"Nhil\", \"Sale\", \"Richmond\", \n",
    "            \"Cobar\", \"Penrith\", \"CoffsHarbour\", \"Nuriootpa\", \"Albany\", \"SydneyAirport\", \"Tuggeranong\",\n",
    "            \"Lauceston\", \"Brisbane\", \"Watsonia\", \"Walpole\", \"AliceSprings\"]\n",
    "\n",
    "#Boucle de remplacement géographique des nans\n",
    "for loc in locgroup:\n",
    "    loclst.append(df[df[\"Location\"] == loc])\n",
    "\n",
    "df_NorfolkIsland = loclst[0]  \n",
    "df_Portland = loclst[1]\n",
    "df_MountGinini = loclst[2]   \n",
    "df_Adelaide = loclst[3]\n",
    "df_Darwin = loclst[4]\n",
    "df_MountGambier = loclst[5]\n",
    "df_GoldCoast = loclst[6]\n",
    "df_Canberra = loclst[7]\n",
    "df_Newcastle = loclst[8]\n",
    "df_Woomera = loclst[9]\n",
    "df_Witchcliffe = loclst[10]\n",
    "df_Moree = loclst[11]\n",
    "df_Wollongong = loclst[12]\n",
    "df_Bendigo = loclst[13]\n",
    "df_Mildura = loclst[14]\n",
    "df_WaggaWagga = loclst[15]\n",
    "df_Dartmoor = loclst[16]\n",
    "df_Hobart = loclst[17]\n",
    "df_SalmonGums = loclst[18]\n",
    "df_Williamtown = loclst[19]\n",
    "df_Townsville = loclst[20]\n",
    "df_PerthAirport = loclst[21]\n",
    "df_Sydney = loclst[22]\n",
    "df_Perth = loclst[23]\n",
    "df_Katherine = loclst[24]\n",
    "df_Albury = loclst[25]\n",
    "df_Ballarat = loclst[26]\n",
    "df_MelbourneAirport = loclst[27]\n",
    "df_BadgerysCreek = loclst[28]\n",
    "df_Melbourne = loclst[29]\n",
    "df_Cairns = loclst[30]\n",
    "df_NorahHead = loclst[31]\n",
    "df_PearceRAAF = loclst[32]\n",
    "df_Uluru = loclst[33]\n",
    "df_Nhil = loclst[34]\n",
    "df_Sale = loclst[35]\n",
    "df_Richmond = loclst[36]\n",
    "df_Cobar = loclst[37]\n",
    "df_Penrith = loclst[38]\n",
    "df_CoffsHarbour = loclst[39]\n",
    "df_Nuriootpa = loclst[40]\n",
    "df_Albany = loclst[41]\n",
    "df_SydneyAirport = loclst[42]\n",
    "df_Tuggeranong = loclst[43]\n",
    "df_Lauceston = loclst[44]\n",
    "df_Brisbane = loclst[45]\n",
    "df_Watsonia = loclst[46]\n",
    "df_Walpole = loclst[47]\n",
    "df_AliceSprings = loclst[48]\n",
    "\n",
    "#Dictionnaire permettant le rappel des regroupements géographiques\n",
    "geogroup = {\"df_Perth2\" : \"Perth, PerthAirport, PearceRAAF\",\n",
    "           \"df_Albany2\" : \"Albany, Witchcliffe, Walpole\",\n",
    "           \"df_Alice2\" : \"AliceSprings, Uluru\",\n",
    "           \"df_Adelaide2\" : \"Adelaide, Nuriootpa\",\n",
    "           \"df_Nhil2\" : \"Nhil, Mildura, Bendigo\",\n",
    "           \"df_Portland2\" : \"Portland, Dartmoor, MountGambier\",\n",
    "           \"df_Melbourne2\" : \"Melbourne, MelbourneAirport, Ballarat, Watsonia, Sale\",\n",
    "           \"df_Albury2\" : \"Albury, WaggaWagga\",\n",
    "           \"df_Canberra2\" : \"Canberra, Tugganong\",\n",
    "           \"df_Sydney2\" : \"Sydney, SydneyAirport, Richmond, Penrith, BadgeryCreeks, Wollongong\",\n",
    "           \"df_Newcastle2\" : \"Newcastle, NorahHead, Williamtown\",\n",
    "           \"df_Cobar2\" : \"Cobar, Moree\",\n",
    "           \"df_Brisbane2\" : \"Brisbane, GoldCoast, CoffsHarbour\",\n",
    "           \"df_Cairns2\" : \"Townsville, Cairns\",\n",
    "           \"df_Hobart2\" : \"Hobart, Launceston\",\n",
    "           \"non_poolés\" : \"SalmonGums, Darwin, Katherine, Woomera, MountGinini, NorfolkIsland\"}\n",
    "\n",
    "#Création des dataframes pour remplacement des nans par regroupement géographique\n",
    "df_Perth2 = pd.concat([df_Perth, df_PerthAirport, df_PearceRAAF])\n",
    "df_Albany2 = pd.concat([df_Albany, df_Witchcliffe, df_Walpole])\n",
    "df_Alice2 = pd.concat([df_AliceSprings, df_Uluru])\n",
    "df_Adelaide2 = pd.concat([df_Adelaide, df_Nuriootpa])\n",
    "df_Nhil2 = pd.concat([df_Nhil, df_Mildura, df_Bendigo])\n",
    "df_Portland2 = pd.concat([df_Portland, df_Dartmoor, df_MountGambier])\n",
    "df_Melbourne2 = pd.concat([df_Melbourne, df_MelbourneAirport, df_Ballarat, df_Watsonia, df_Sale])\n",
    "df_Albury2 = pd.concat([df_Albury, df_WaggaWagga])\n",
    "df_Canberra2 = pd.concat([df_Canberra, df_Tuggeranong])\n",
    "df_Sydney2 = pd.concat([df_Sydney, df_SydneyAirport, df_Richmond, df_Penrith, df_BadgerysCreek, df_Wollongong])\n",
    "df_Newcastle2 = pd.concat([df_Newcastle, df_NorahHead, df_Williamtown])\n",
    "df_Cobar2 = pd.concat([df_Cobar, df_Moree])\n",
    "df_Brisbane2 = pd.concat([df_Brisbane, df_GoldCoast, df_CoffsHarbour])\n",
    "df_Cairns2 = pd.concat([df_Townsville, df_Cairns])\n",
    "df_Hobart2 = pd.concat([df_Hobart, df_Lauceston])\n",
    "\n",
    "geolist_brute = [df_Perth2, df_Albany2, df_Alice2, df_Adelaide2, df_Nhil2, df_Portland2, df_Melbourne2,\n",
    "df_Albury2, df_Canberra2, df_Sydney2, df_Newcastle2, df_Cobar2, df_Brisbane2, df_Cairns2, df_Hobart2,\n",
    "           df_SalmonGums, df_Darwin, df_Katherine, df_Woomera, df_MountGinini, df_NorfolkIsland]\n",
    "\n",
    "geolist_str = [\"df_Perth2\", \"df_Albany2\", \"df_Alice2\", \"df_Adelaide2\", \"df_Nhil2\", \"df_Portland2\", \"df_Melbourne2\",\n",
    "\"df_Albury2\", \"df_Canberra2\", \"df_Sydney2\", \"df_Newcastle2\", \"df_Cobar2\", \"df_Brisbane2\", \"df_Cairns2\", \"df_Hobart2\",\n",
    "           \"df_SalmonGums\", \"df_Darwin\", \"df_Katherine\", \"df_Woomera\", \"df_MountGinini\", \"df_NorfolkIsland\"]\n",
    "#Remplacement des nans et régénération des df groupés\n",
    "\n",
    "geolist_clean = []\n",
    "k = 0\n",
    "\n",
    "for df in geolist_brute:\n",
    "    df_temp = df\n",
    "    print(\"In progress: {}. {} nans before cleaning ({} %)\".format(geolist_str[k], geolist_brute[k].isna().sum().sum(), round(100*(geolist_brute[k].isna().sum().sum())/(geolist_brute[k].shape[0]*geolist_brute[k].shape[1]),1)))\n",
    "\n",
    "    #Elimination des nans sur RainToday et RainTomorrow\n",
    "    df_temp.dropna(axis = 0, how = \"any\", inplace = True, subset = [\"RainToday\", \"RainTomorrow\"])\n",
    "\n",
    "    for i in range(1,13,1):\n",
    "                  \n",
    "        #Remplacement des nans de MinTemp\n",
    "        df_temp.MinTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.MinTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.MinTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.MinTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.MinTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.MinTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "            \n",
    "        #Remplacement des nans de MaxTemp\n",
    "        df_temp.MaxTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.MaxTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.MaxTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.MaxTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.MaxTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.MaxTemp[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "        \n",
    "        #Remplacement de Rainfall\n",
    "        df_temp.Rainfall[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Rainfall[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Rainfall[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].median())\n",
    "        df_temp.Rainfall[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Rainfall[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Rainfall[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].median())\n",
    "                \n",
    "        #Evaporation :\n",
    "        df_temp.Evaporation[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Evaporation[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Evaporation[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].median())\n",
    "        df_temp.Evaporation[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Evaporation[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Evaporation[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].median())\n",
    "        \n",
    "        #Sunshine :\n",
    "        df_temp.Sunshine[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Sunshine[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Sunshine[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].median())\n",
    "        df_temp.Sunshine[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Sunshine[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Sunshine[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].median())\n",
    "        \n",
    "        #WindGustdir :\n",
    "        df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mode())\n",
    "        df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mode())\n",
    "        \n",
    "        #WindGustSpeed :\n",
    "        df_temp.WindGustSpeed[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.WindGustSpeed[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.WindGustSpeed[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.WindGustSpeed[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.WindGustSpeed[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.WindGustSpeed[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "                \n",
    "        #WindDir9am :\n",
    "        df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mode([0]))\n",
    "        df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mode([0]))\n",
    "                \n",
    "        #WindDir3pm :\n",
    "        df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mode([0]))\n",
    "        df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.WindGustDir[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mode([0]))\n",
    "        \n",
    "        #WindSpeed9am :\n",
    "        df_temp.WindSpeed9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.WindSpeed9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.WindSpeed9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.WindSpeed9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.WindSpeed9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.WindSpeed9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "        \n",
    "        #WindSpeed3pm :\n",
    "        df_temp.WindSpeed3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.WindSpeed3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.WindSpeed3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.WindSpeed3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.WindSpeed3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.WindSpeed3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "           \n",
    "        #Humidity9am\n",
    "        df_temp.Humidity9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Humidity9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Humidity9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.Humidity9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Humidity9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Humidity9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "            \n",
    "        #Humidity3pm\n",
    "        df_temp.Humidity3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Humidity3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Humidity3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.Humidity3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Humidity3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Humidity3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "\n",
    "        #Pressure9am\n",
    "        df_temp.Pressure9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Pressure9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Pressure9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.Pressure9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Pressure9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Pressure9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "\n",
    "        #Pressure9am\n",
    "        df_temp.Pressure3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Pressure3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Pressure3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.Pressure3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Pressure3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Pressure3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "\n",
    "        #Cloud9am\n",
    "        df_temp.Cloud9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Cloud9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Cloud9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.Cloud9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Cloud9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Cloud9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "\n",
    "        #Cloud3pm\n",
    "        df_temp.Cloud3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Cloud3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Cloud3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.Cloud3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Cloud3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Cloud3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "\n",
    "        #Temp9am\n",
    "        df_temp.Temp9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Temp9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Temp9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.Temp9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Temp9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Temp9am[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "            \n",
    "        #Temp3pm\n",
    "        df_temp.Temp3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")] = df_temp.Temp3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].fillna(df_temp.Temp3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"Yes\")].mean())\n",
    "        df_temp.Temp3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")] = df_temp.Temp3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].fillna(df_temp.Temp3pm[(df_temp[\"Month\"] == i) & (df_temp[\"RainToday\"] == \"No\")].mean())\n",
    "        \n",
    "    geolist_clean.append(df_temp)\n",
    "    print(\"\\tCleaning done: {}. {} nans remaining ({} %)\".format(geolist_str[k], df_temp.isna().sum().sum(), round(100*(df_temp.isna().sum().sum())/(df_temp.shape[0]*df_temp.shape[1]),1)))\n",
    "    print(\"\\n---------------------------------------------------------------\")\n",
    "    k+=1\n",
    "    \n",
    "print(\"Cleaning complete.\")\n",
    "\n",
    "df_Perth2 = geolist_clean[0]\n",
    "df_Albany2 = geolist_clean[1]\n",
    "df_Alice2 = geolist_clean[2]\n",
    "df_Adelaide2 = geolist_clean[3]\n",
    "df_Nhil2 = geolist_clean[4]\n",
    "df_Portland2 = geolist_clean[5]\n",
    "df_Melbourne2 = geolist_clean[6]\n",
    "df_Albury2 = geolist_clean[7]\n",
    "df_Canberra2 = geolist_clean[8]\n",
    "df_Sydney2 = geolist_clean[9]\n",
    "df_Newcastle2 = geolist_clean[10]\n",
    "df_Cobar2 = geolist_clean[11]\n",
    "df_Brisbane2 = geolist_clean[12]\n",
    "df_Cairns2 = geolist_clean[13]\n",
    "df_Hobart2 = geolist_clean[14]\n",
    "df_SalmonGums = geolist_clean[15]\n",
    "df_Darwin = geolist_clean[16]\n",
    "df_Katherine = geolist_clean[17]\n",
    "df_Woomera = geolist_clean[18]\n",
    "df_MountGinini = geolist_clean[19]\n",
    "df_NorfolkIsland = geolist_clean[20]\n",
    "\n",
    "#Reconstitution du df global\n",
    "\n",
    "data_full = pd.concat(geolist_clean)\n",
    "\n",
    "#Suppression des variables avec trop de nans\n",
    "\n",
    "data = data_full.drop([\"Sunshine\", \"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"], axis = 1)\n",
    "\n",
    "#Supression des nans restant\n",
    "data = data.dropna()\n",
    "\n",
    "display(Markdown(\"\"\"Il y avait initialement <b>{} valeurs manquantes</b> dans la base de données (<b>{} %</b> des données totales), répartis sur {} entrées.\n",
    "Le preprocessing a permis de réduire le nombre de valeurs manquantes à <b>{}</b> : <b>{} %</b> des valeurs manquantes initiales ont été remplacés.\n",
    "Après suppression de 4 colonnes comportant trop de valeurs manquantes, et suppression des valeurs manquantes restantes, il reste <b>{} relevés</b> dans la base.\n",
    "Au total, <b>{} %</b> des relevés météorologiques ont été <b>conservés</b>.\n",
    "\"\"\".format(\n",
    "    df_saved.isna().sum().sum(),\n",
    "    round(100*df_saved.isna().sum().sum()/(df_saved.shape[0]*df_saved.shape[1]),1),\n",
    "    df_saved.shape[0],\n",
    "    data_full.isna().sum().sum(),\n",
    "    100-round(100*data_full.isna().sum().sum()/df_saved.isna().sum().sum(), 1),\n",
    "    data.shape[0],\n",
    "    round(100*data.shape[0]/df_saved.shape[0],1)\n",
    ")))\n",
    "\n",
    "#CREATION DES VARIABLES SUPPLEMENTAIRES\n",
    "#State, Year, Month, Day\n",
    "\n",
    "#WindSpeedDiff, HumidityDiff, TempDiff\n",
    "data[\"WindSpeedDiff\"] = data[\"WindSpeed3pm\"] - data[\"WindSpeed9am\"]\n",
    "data[\"HumidityDiff\"] = data[\"Humidity3pm\"] - data[\"Humidity9am\"]\n",
    "data[\"TempDiff\"] = data[\"Temp3pm\"] - data[\"Temp9am\"]\n",
    "\n",
    "#MinMaxDiff\n",
    "data[\"MinMaxDiff\"] = data[\"MaxTemp\"] - data[\"MinTemp\"]\n",
    "\n",
    "#PressureDiff\n",
    "data[\"PressureDiff\"] = data[\"Pressure3pm\"] - data[\"Pressure9am\"]\n",
    "\n",
    "#CloudDiff\n",
    "data[\"CloudDiff\"] = data[\"Cloud3pm\"] - data[\"Cloud9am\"]\n",
    "\n",
    "#Encodage de RainToday et RainTomorrow\n",
    "encoder = LabelEncoder()\n",
    "LE_cols = [\"RainToday\", \"RainTomorrow\"]\n",
    "for col in LE_cols:\n",
    "    data[col] = encoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519d10d",
   "metadata": {},
   "source": [
    "<h2><font color = \"navy\">Création des modèles</font></h2>\n",
    "<ul><li>Préparation des ensembles d'entrainement et de test.</li><li>Évaluation des performances du modèle.</li><li>Modulation des différents paramètres.</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea58b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = data.drop([\"RainTomorrow\", \"Date\", \"Year\", \"Month\", \"Day\", \"State\", \"Location\"], axis = 1)\n",
    "target = data[\"RainTomorrow\"]\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "Y = encoder.fit_transform(target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, Y, test_size = 0.2, random_state = 55) \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ceac83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2><center>PREMIER MODÈLE DE DEEP LEARNING</h2></center>\n",
       "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "3229/3229 [==============================] - 3s 958us/step - loss: 0.3538 - accuracy: 0.8476 - val_loss: 0.3424 - val_accuracy: 0.8527\n",
      "Epoch 2/6\n",
      "3229/3229 [==============================] - 3s 951us/step - loss: 0.3448 - accuracy: 0.8504 - val_loss: 0.3368 - val_accuracy: 0.8556\n",
      "Epoch 3/6\n",
      "3229/3229 [==============================] - 3s 872us/step - loss: 0.3416 - accuracy: 0.8522 - val_loss: 0.3347 - val_accuracy: 0.8554\n",
      "Epoch 4/6\n",
      "3229/3229 [==============================] - 3s 868us/step - loss: 0.3396 - accuracy: 0.8529 - val_loss: 0.3336 - val_accuracy: 0.8569\n",
      "Epoch 5/6\n",
      "3229/3229 [==============================] - 3s 911us/step - loss: 0.3385 - accuracy: 0.8530 - val_loss: 0.3339 - val_accuracy: 0.8567\n",
      "Epoch 6/6\n",
      "3229/3229 [==============================] - 3s 866us/step - loss: 0.3372 - accuracy: 0.8534 - val_loss: 0.3318 - val_accuracy: 0.8562\n",
      "808/808 [==============================] - 0s 585us/step - loss: 0.3318 - accuracy: 0.8562\n",
      "[0.331760048866272, 0.8562301397323608]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Récapitulatif du modèle :</font></u></h4>\n",
       "Ce premier modèle avait 2 couches denses :\n",
       "<ul><li>la première avec <b>25 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la seconde avec <b>50 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
       "<li> apprentissage sur <b>6 epochs</b> par batch de <b>32</b>.</li></ul>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 22)]              0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 25)                575       \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 50)                1300      \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,977\n",
      "Trainable params: 1,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
       "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>72.18 %</b> (<i>recall = <b>54.36 %</b></i>)</li>\n",
       "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>88.23 %</b> (<i>recall = <b>94.23 %</b></i>).\n",
       "<li>La précision globale du modèle est de <b>85.62 %</b>.</li></ul>\n",
       "Les paramètres de ce premier modèle ont été fixés de façon plus ou moins arbritraire. Les \n",
       "performances de ce modèle sont globalement satisfaisantes, voire très satisfaisantes pour la détection des jours sans pluie.\n",
       "Il serait toutefois intéressant d'améliorer la prédiction de jours de pluie.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Rapport de classification</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     20250\n",
      "           1       0.72      0.54      0.62      5576\n",
      "\n",
      "    accuracy                           0.86     25826\n",
      "   macro avg       0.80      0.74      0.77     25826\n",
      "weighted avg       0.85      0.86      0.85     25826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Matrice de confusion</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19082  1168]\n",
      " [ 2545  3031]]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"\"\"<h2><center>PREMIER MODÈLE DE DEEP LEARNING</h2></center>\n",
    "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>\"\"\"))\n",
    "EPOCHS = 6\n",
    "BATCHS = 32\n",
    "\n",
    "UNITS1 = 25\n",
    "UNITS2 = 50\n",
    "UNITS3 = None\n",
    "UNITS4 = None\n",
    "UNITS5 = None\n",
    "UNITSOUT = 2\n",
    "\n",
    "ACTIV1 = \"relu\"\n",
    "ACTIV2 = \"relu\"\n",
    "ACTIV3 = None\n",
    "ACTIV4 = None\n",
    "ACTIV5 = None\n",
    "\n",
    "inputs = Input(shape = X_train_scaled.shape[1], name = \"Input\")\n",
    "dense1 = Dense(units = UNITS1, activation = ACTIV1, kernel_initializer = \"normal\", name = \"Dense_1\")\n",
    "dense2 = Dense(units = UNITS2, activation = ACTIV2, kernel_initializer = \"normal\", name = \"Dense_2\")\n",
    "dense3 = Dense(units = UNITSOUT, activation = \"softmax\", name = \"Dense_3\")\n",
    "\n",
    "x = dense1(inputs)\n",
    "x = dense2(x)\n",
    "outputs = dense3(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "training_history = model.fit(X_train_scaled, y_train, epochs = EPOCHS, batch_size = BATCHS, validation_data=(X_test_scaled,y_test))\n",
    "\n",
    "#calcul du score\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "print(score)\n",
    "\n",
    "#prédiction\n",
    "test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "y_test_class = y_test\n",
    "y_pred_class = np.argmax(test_pred, axis = 1)\n",
    "\n",
    "#Résultats\n",
    "precis = classification_report(y_test_class, y_pred_class,output_dict=True)\n",
    "\n",
    "#Output\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Récapitulatif du modèle :</font></u></h4>\n",
    "Ce premier modèle avait 2 couches denses :\n",
    "<ul><li>la première avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la seconde avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
    "<li> apprentissage sur <b>{} epochs</b> par batch de <b>{}</b>.</li></ul>\n",
    "\"\"\".format(UNITS1, ACTIV1, UNITS2, ACTIV2, EPOCHS, BATCHS)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
    "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>)</li>\n",
    "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>).\n",
    "<li>La précision globale du modèle est de <b>{} %</b>.</li></ul>\n",
    "Les paramètres de ce premier modèle ont été fixés de façon plus ou moins arbritraire. Les \n",
    "performances de ce modèle sont globalement satisfaisantes, voire très satisfaisantes pour la détection des jours sans pluie.\n",
    "Il serait toutefois intéressant d'améliorer la prédiction de jours de pluie.\n",
    "\"\"\".format(\n",
    "    round(100*precis[\"1\"][\"precision\"],2),\n",
    "    round(100*precis[\"1\"][\"recall\"],2),\n",
    "    round(100*precis[\"0\"][\"precision\"],2),\n",
    "    round(100*precis[\"0\"][\"recall\"],2),\n",
    "    round(100*precis[\"accuracy\"],2)\n",
    ")))\n",
    "\n",
    "display(Markdown(\"<i><b>Rapport de classification</b></i>\"))\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "display(Markdown(\"<i><b>Matrice de confusion</b></i>\"))\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e76f69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2><center>EFFET DU NOMBRE DE NEURONES SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
       "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "3229/3229 [==============================] - 5s 2ms/step - loss: 0.3502 - accuracy: 0.8483 - val_loss: 0.3383 - val_accuracy: 0.8543\n",
      "Epoch 2/6\n",
      "3229/3229 [==============================] - 5s 2ms/step - loss: 0.3408 - accuracy: 0.8521 - val_loss: 0.3322 - val_accuracy: 0.8564\n",
      "Epoch 3/6\n",
      "3229/3229 [==============================] - 5s 2ms/step - loss: 0.3371 - accuracy: 0.8537 - val_loss: 0.3303 - val_accuracy: 0.8587\n",
      "Epoch 4/6\n",
      "3229/3229 [==============================] - 5s 2ms/step - loss: 0.3340 - accuracy: 0.8551 - val_loss: 0.3301 - val_accuracy: 0.8574\n",
      "Epoch 5/6\n",
      "3229/3229 [==============================] - 5s 2ms/step - loss: 0.3318 - accuracy: 0.8558 - val_loss: 0.3401 - val_accuracy: 0.8551\n",
      "Epoch 6/6\n",
      "3229/3229 [==============================] - 5s 2ms/step - loss: 0.3294 - accuracy: 0.8572 - val_loss: 0.3317 - val_accuracy: 0.8576\n",
      "808/808 [==============================] - 1s 781us/step - loss: 0.3317 - accuracy: 0.8576\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
       "Ce modèle avait 2 couches denses :\n",
       "<ul><li>la première avec <b>250 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la seconde avec <b>500 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
       "<li> apprentissage sur <b>6 epochs</b> par batch de <b>32</b>.</li></ul>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 22)]              0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 250)               5750      \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 500)               125500    \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 2)                 1002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,252\n",
      "Trainable params: 132,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
       "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>76.94 %</b> (<i>recall = <b>48.6 %</b></i>).</li>\n",
       "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>87.15 %</b> (<i>recall = <b>95.99 %</b></i>).</li>\n",
       "<li>La précision globale du modèle est de <b>85.76 %</b>.</li></ul>\n",
       "Le simple ajout de neurones (ici 10 fois plus nombreux dans chaque couche par rapport au modèle initial) \n",
       "ne semble pas modifier les performances.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Rapport de classification</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     20250\n",
      "           1       0.77      0.49      0.60      5576\n",
      "\n",
      "    accuracy                           0.86     25826\n",
      "   macro avg       0.82      0.72      0.75     25826\n",
      "weighted avg       0.85      0.86      0.84     25826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Matrice de confusion</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19438   812]\n",
      " [ 2866  2710]]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"\"\"<h2><center>EFFET DU NOMBRE DE NEURONES SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
    "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>\"\"\"))\n",
    "\n",
    "EPOCHS = 6\n",
    "BATCHS = 32\n",
    "\n",
    "UNITS1 = 250\n",
    "UNITS2 = 500\n",
    "UNITS3 = None\n",
    "UNITS4 = None\n",
    "UNITS5 = None\n",
    "UNITSOUT = 2\n",
    "\n",
    "ACTIV1 = \"relu\"\n",
    "ACTIV2 = \"relu\"\n",
    "ACTIV3 = None\n",
    "ACTIV4 = None\n",
    "ACTIV5 = None\n",
    "\n",
    "inputs = Input(shape = X_train_scaled.shape[1], name = \"Input\")\n",
    "dense1 = Dense(units = UNITS1, activation = ACTIV1, kernel_initializer = \"normal\", name = \"Dense_1\")\n",
    "dense2 = Dense(units = UNITS2, activation = ACTIV2, kernel_initializer = \"normal\", name = \"Dense_2\")\n",
    "dense3 = Dense(units = UNITSOUT, activation = \"softmax\", name = \"Dense_3\")\n",
    "\n",
    "\n",
    "x = dense1(inputs)\n",
    "x = dense2(x)\n",
    "outputs = dense3(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "training_history = model.fit(X_train_scaled, y_train, epochs = EPOCHS, batch_size = BATCHS, validation_data=(X_test_scaled,y_test))\n",
    "\n",
    "#calcul du score\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "#prédiction\n",
    "test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "y_test_class = y_test\n",
    "y_pred_class = np.argmax(test_pred, axis = 1)\n",
    "\n",
    "#Résultats\n",
    "precis = classification_report(y_test_class, y_pred_class,output_dict=True)\n",
    "\n",
    "#Output\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
    "Ce modèle avait 2 couches denses :\n",
    "<ul><li>la première avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la seconde avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
    "<li> apprentissage sur <b>{} epochs</b> par batch de <b>{}</b>.</li></ul>\n",
    "\"\"\".format(UNITS1, ACTIV1, UNITS2, ACTIV2, EPOCHS, BATCHS)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
    "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>).</li>\n",
    "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>).</li>\n",
    "<li>La précision globale du modèle est de <b>{} %</b>.</li></ul>\n",
    "Le simple ajout de neurones (ici 10 fois plus nombreux dans chaque couche par rapport au modèle initial) \n",
    "ne semble pas modifier les performances.\n",
    "\"\"\".format(\n",
    "    round(100*precis[\"1\"][\"precision\"],2),\n",
    "    round(100*precis[\"1\"][\"recall\"],2),\n",
    "    round(100*precis[\"0\"][\"precision\"],2),\n",
    "    round(100*precis[\"0\"][\"recall\"],2),\n",
    "    round(100*precis[\"accuracy\"],2)\n",
    ")))\n",
    "\n",
    "display(Markdown(\"<i><b>Rapport de classification</b></i>\"))\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "display(Markdown(\"<i><b>Matrice de confusion</b></i>\"))\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb5dcf74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2><center>EFFET DU NOMBRE D'EPOCHS SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
       "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "3229/3229 [==============================] - 3s 905us/step - loss: 0.3538 - accuracy: 0.8466 - val_loss: 0.3391 - val_accuracy: 0.8535\n",
      "Epoch 2/18\n",
      "3229/3229 [==============================] - 3s 884us/step - loss: 0.3447 - accuracy: 0.8510 - val_loss: 0.3371 - val_accuracy: 0.8545\n",
      "Epoch 3/18\n",
      "3229/3229 [==============================] - 3s 862us/step - loss: 0.3427 - accuracy: 0.8509 - val_loss: 0.3404 - val_accuracy: 0.8514\n",
      "Epoch 4/18\n",
      "3229/3229 [==============================] - 3s 866us/step - loss: 0.3411 - accuracy: 0.8516 - val_loss: 0.3364 - val_accuracy: 0.8545\n",
      "Epoch 5/18\n",
      "3229/3229 [==============================] - 3s 865us/step - loss: 0.3396 - accuracy: 0.8528 - val_loss: 0.3365 - val_accuracy: 0.8542\n",
      "Epoch 6/18\n",
      "3229/3229 [==============================] - 3s 863us/step - loss: 0.3378 - accuracy: 0.8525 - val_loss: 0.3351 - val_accuracy: 0.8551\n",
      "Epoch 7/18\n",
      "3229/3229 [==============================] - 3s 865us/step - loss: 0.3371 - accuracy: 0.8537 - val_loss: 0.3392 - val_accuracy: 0.8512\n",
      "Epoch 8/18\n",
      "3229/3229 [==============================] - 3s 869us/step - loss: 0.3357 - accuracy: 0.8543 - val_loss: 0.3328 - val_accuracy: 0.8556\n",
      "Epoch 9/18\n",
      "3229/3229 [==============================] - 3s 881us/step - loss: 0.3347 - accuracy: 0.8549 - val_loss: 0.3329 - val_accuracy: 0.8555\n",
      "Epoch 10/18\n",
      "3229/3229 [==============================] - 3s 873us/step - loss: 0.3341 - accuracy: 0.8555 - val_loss: 0.3323 - val_accuracy: 0.8571\n",
      "Epoch 11/18\n",
      "3229/3229 [==============================] - 3s 869us/step - loss: 0.3329 - accuracy: 0.8555 - val_loss: 0.3328 - val_accuracy: 0.8556\n",
      "Epoch 12/18\n",
      "3229/3229 [==============================] - 3s 865us/step - loss: 0.3324 - accuracy: 0.8553 - val_loss: 0.3332 - val_accuracy: 0.8563\n",
      "Epoch 13/18\n",
      "3229/3229 [==============================] - 3s 869us/step - loss: 0.3319 - accuracy: 0.8553 - val_loss: 0.3327 - val_accuracy: 0.8565\n",
      "Epoch 14/18\n",
      "3229/3229 [==============================] - 3s 872us/step - loss: 0.3312 - accuracy: 0.8563 - val_loss: 0.3324 - val_accuracy: 0.8563\n",
      "Epoch 15/18\n",
      "3229/3229 [==============================] - 3s 880us/step - loss: 0.3309 - accuracy: 0.8563 - val_loss: 0.3336 - val_accuracy: 0.8544\n",
      "Epoch 16/18\n",
      "3229/3229 [==============================] - 3s 872us/step - loss: 0.3303 - accuracy: 0.8559 - val_loss: 0.3326 - val_accuracy: 0.8558\n",
      "Epoch 17/18\n",
      "3229/3229 [==============================] - 3s 864us/step - loss: 0.3296 - accuracy: 0.8564 - val_loss: 0.3331 - val_accuracy: 0.8573\n",
      "Epoch 18/18\n",
      "3229/3229 [==============================] - 3s 864us/step - loss: 0.3291 - accuracy: 0.8564 - val_loss: 0.3329 - val_accuracy: 0.8565\n",
      "808/808 [==============================] - 0s 583us/step - loss: 0.3329 - accuracy: 0.8565\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
       "Ce modèle avait 2 couches denses :\n",
       "<ul><li>la première avec <b>25 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la seconde avec <b>50 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
       "<li> apprentissage sur <b>18 epochs</b> par batch de <b>32</b>.</li></ul>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 22)]              0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 25)                575       \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 50)                1300      \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,977\n",
      "Trainable params: 1,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
       "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>71.1 %</b> (<i>recall = <b>56.51 %</b></i>)</li>\n",
       "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>88.67 %</b> (<i>recall = <b>93.67 %</b></i>).\n",
       "<li>La précision globale du modèle est de <b>85.65 %</b>.</li></ul>\n",
       "L'entrainement sur un nombre plus important d'epochs (ici 18 soit 3 fois plus par rapport au modèle initial) \n",
       "ne semble pas modifier les performances.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Rapport de classification</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91     20250\n",
      "           1       0.71      0.57      0.63      5576\n",
      "\n",
      "    accuracy                           0.86     25826\n",
      "   macro avg       0.80      0.75      0.77     25826\n",
      "weighted avg       0.85      0.86      0.85     25826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Matrice de confusion</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18969  1281]\n",
      " [ 2425  3151]]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"\"\"<h2><center>EFFET DU NOMBRE D'EPOCHS SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
    "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>\"\"\"))\n",
    "\n",
    "EPOCHS = 18\n",
    "BATCHS = 32\n",
    "\n",
    "UNITS1 = 25\n",
    "UNITS2 = 50\n",
    "UNITS3 = None\n",
    "UNITS4 = None\n",
    "UNITS5 = None\n",
    "UNITSOUT = 2\n",
    "\n",
    "ACTIV1 = \"relu\"\n",
    "ACTIV2 = \"relu\"\n",
    "ACTIV3 = None\n",
    "ACTIV4 = None\n",
    "ACTIV5 = None\n",
    "\n",
    "inputs = Input(shape = X_train_scaled.shape[1], name = \"Input\")\n",
    "dense1 = Dense(units = UNITS1, activation = ACTIV1, kernel_initializer = \"normal\", name = \"Dense_1\")\n",
    "dense2 = Dense(units = UNITS2, activation = ACTIV2, kernel_initializer = \"normal\", name = \"Dense_2\")\n",
    "dense3 = Dense(units = UNITSOUT, activation = \"softmax\", name = \"Dense_3\")\n",
    "\n",
    "x = dense1(inputs)\n",
    "x = dense2(x)\n",
    "outputs = dense3(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "training_history = model.fit(X_train_scaled, y_train, epochs = EPOCHS, batch_size = BATCHS, validation_data=(X_test_scaled,y_test))\n",
    "\n",
    "#calcul du score\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "#prédiction\n",
    "test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "y_test_class = y_test\n",
    "y_pred_class = np.argmax(test_pred, axis = 1)\n",
    "\n",
    "#Résultats\n",
    "precis = classification_report(y_test_class, y_pred_class,output_dict=True)\n",
    "\n",
    "#Output\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
    "Ce modèle avait 2 couches denses :\n",
    "<ul><li>la première avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la seconde avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
    "<li> apprentissage sur <b>{} epochs</b> par batch de <b>{}</b>.</li></ul>\n",
    "\"\"\".format(UNITS1, ACTIV1, UNITS2, ACTIV2, EPOCHS, BATCHS)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
    "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>)</li>\n",
    "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>).\n",
    "<li>La précision globale du modèle est de <b>{} %</b>.</li></ul>\n",
    "L'entrainement sur un nombre plus important d'epochs (ici 18 soit 3 fois plus par rapport au modèle initial) \n",
    "ne semble pas modifier les performances.\n",
    "\"\"\".format(\n",
    "    round(100*precis[\"1\"][\"precision\"],2),\n",
    "    round(100*precis[\"1\"][\"recall\"],2),\n",
    "    round(100*precis[\"0\"][\"precision\"],2),\n",
    "    round(100*precis[\"0\"][\"recall\"],2),\n",
    "    round(100*precis[\"accuracy\"],2)\n",
    ")))\n",
    "\n",
    "display(Markdown(\"<i><b>Rapport de classification</b></i>\"))\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "display(Markdown(\"<i><b>Matrice de confusion</b></i>\"))\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cce68ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2><center>EFFET DE LA TAILLE DES BATCHS SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
       "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.3817 - accuracy: 0.8357 - val_loss: 0.3429 - val_accuracy: 0.8505\n",
      "Epoch 2/6\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8501 - val_loss: 0.3390 - val_accuracy: 0.8546\n",
      "Epoch 3/6\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.3439 - accuracy: 0.8513 - val_loss: 0.3375 - val_accuracy: 0.8543\n",
      "Epoch 4/6\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8510 - val_loss: 0.3356 - val_accuracy: 0.8551\n",
      "Epoch 5/6\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8522 - val_loss: 0.3354 - val_accuracy: 0.8548\n",
      "Epoch 6/6\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8522 - val_loss: 0.3343 - val_accuracy: 0.8555\n",
      "808/808 [==============================] - 0s 590us/step - loss: 0.3343 - accuracy: 0.8555\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
       "Ce modèle avait 2 couches denses :\n",
       "<ul><li>la première avec <b>25 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la seconde avec <b>50 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
       "<li> apprentissage sur <b>6 epochs</b> par batch de <b>320</b>.</li></ul>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 22)]              0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 25)                575       \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 50)                1300      \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,977\n",
      "Trainable params: 1,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
       "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>73.54 %</b> (<i>recall = <b>51.63 %</b></i>)</li>\n",
       "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>87.69 %</b> (<i>recall = <b>94.88 %</b></i>).\n",
       "<li>La précision globale du modèle est de <b>85.55 %</b>.</li></ul>\n",
       "L'entrainement sur des batchs de plus grande taille (ici 320 soit 10 fois plus grands par rapport au modèle initial) \n",
       "ne semble pas modifier les performances, en revanche la vitesse d'execution du modèle est considérablement réduite.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Rapport de classification</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     20250\n",
      "           1       0.74      0.52      0.61      5576\n",
      "\n",
      "    accuracy                           0.86     25826\n",
      "   macro avg       0.81      0.73      0.76     25826\n",
      "weighted avg       0.85      0.86      0.85     25826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Matrice de confusion</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19214  1036]\n",
      " [ 2697  2879]]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"\"\"<h2><center>EFFET DE LA TAILLE DES BATCHS SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
    "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>\"\"\"))\n",
    "\n",
    "EPOCHS = 6\n",
    "BATCHS = 320\n",
    "\n",
    "UNITS1 = 25\n",
    "UNITS2 = 50\n",
    "UNITS3 = None\n",
    "UNITS4 = None\n",
    "UNITS5 = None\n",
    "UNITSOUT = 2\n",
    "\n",
    "ACTIV1 = \"relu\"\n",
    "ACTIV2 = \"relu\"\n",
    "ACTIV3 = None\n",
    "ACTIV4 = None\n",
    "ACTIV5 = None\n",
    "\n",
    "inputs = Input(shape = X_train_scaled.shape[1], name = \"Input\")\n",
    "dense1 = Dense(units = UNITS1, activation = ACTIV1, kernel_initializer = \"normal\", name = \"Dense_1\")\n",
    "dense2 = Dense(units = UNITS2, activation = ACTIV2, kernel_initializer = \"normal\", name = \"Dense_2\")\n",
    "dense3 = Dense(units = UNITSOUT, activation = \"softmax\", name = \"Dense_3\")\n",
    "\n",
    "x = dense1(inputs)\n",
    "x = dense2(x)\n",
    "outputs = dense3(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "training_history = model.fit(X_train_scaled, y_train, epochs = EPOCHS, batch_size = BATCHS, validation_data=(X_test_scaled,y_test))\n",
    "\n",
    "#calcul du score\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "#prédiction\n",
    "test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "y_test_class = y_test\n",
    "y_pred_class = np.argmax(test_pred, axis = 1)\n",
    "\n",
    "#Résultats\n",
    "precis = classification_report(y_test_class, y_pred_class,output_dict=True)\n",
    "\n",
    "#Output\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
    "Ce modèle avait 2 couches denses :\n",
    "<ul><li>la première avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la seconde avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
    "<li> apprentissage sur <b>{} epochs</b> par batch de <b>{}</b>.</li></ul>\n",
    "\"\"\".format(UNITS1, ACTIV1, UNITS2, ACTIV2, EPOCHS, BATCHS)))\n",
    "\n",
    "model.summary()\n",
    "                 \n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
    "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>)</li>\n",
    "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>).\n",
    "<li>La précision globale du modèle est de <b>{} %</b>.</li></ul>\n",
    "L'entrainement sur des batchs de plus grande taille (ici 320 soit 10 fois plus grands par rapport au modèle initial) \n",
    "ne semble pas modifier les performances, en revanche la vitesse d'execution du modèle est considérablement réduite.\n",
    "\"\"\".format(\n",
    "    round(100*precis[\"1\"][\"precision\"],2),\n",
    "    round(100*precis[\"1\"][\"recall\"],2),\n",
    "    round(100*precis[\"0\"][\"precision\"],2),\n",
    "    round(100*precis[\"0\"][\"recall\"],2),\n",
    "    round(100*precis[\"accuracy\"],2)\n",
    ")))\n",
    "\n",
    "display(Markdown(\"<i><b>Rapport de classification</b></i>\"))\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "display(Markdown(\"<i><b>Matrice de confusion</b></i>\"))\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7d62ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2><center>EFFET DES FONCTIONS D'ACTIVATION SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
       "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "3229/3229 [==============================] - 3s 903us/step - loss: 0.3589 - accuracy: 0.8446 - val_loss: 0.3478 - val_accuracy: 0.8514\n",
      "Epoch 2/6\n",
      "3229/3229 [==============================] - 3s 882us/step - loss: 0.3538 - accuracy: 0.8468 - val_loss: 0.3499 - val_accuracy: 0.8507\n",
      "Epoch 3/6\n",
      "3229/3229 [==============================] - 3s 880us/step - loss: 0.3514 - accuracy: 0.8471 - val_loss: 0.3434 - val_accuracy: 0.8526\n",
      "Epoch 4/6\n",
      "3229/3229 [==============================] - 3s 864us/step - loss: 0.3482 - accuracy: 0.8482 - val_loss: 0.3412 - val_accuracy: 0.8538\n",
      "Epoch 5/6\n",
      "3229/3229 [==============================] - 3s 872us/step - loss: 0.3461 - accuracy: 0.8495 - val_loss: 0.3418 - val_accuracy: 0.8535\n",
      "Epoch 6/6\n",
      "3229/3229 [==============================] - 3s 875us/step - loss: 0.3449 - accuracy: 0.8496 - val_loss: 0.3436 - val_accuracy: 0.8504\n",
      "808/808 [==============================] - 1s 615us/step - loss: 0.3436 - accuracy: 0.8504\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
       "Ce modèle avait 2 couches denses :\n",
       "<ul><li>la première avec <b>25 neurones</b> et une fonction d'activation <b>tanh</b>.</li>\n",
       "<li> la seconde avec <b>50 neurones</b> et une fonction d'activation <b>tanh</b>.</li>\n",
       "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
       "<li> apprentissage sur <b>6 epochs</b> par batch de <b>32</b>.</li></ul>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 22)]              0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 25)                575       \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 50)                1300      \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,977\n",
      "Trainable params: 1,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
       "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>67.95 %</b> (<i>recall = <b>58.11 %</b></i>)</li>\n",
       "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>88.91 %</b> (<i>recall = <b>92.45 %</b></i>).\n",
       "<li>La précision globale du modèle est de <b>85.04 %</b>.</li></ul>\n",
       "L'activation des couches denses par la fonction tangente hyperbolique (au lieu de relu dans modèle initial) \n",
       "ne semble pas modifier les performances.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Rapport de classification</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91     20250\n",
      "           1       0.68      0.58      0.63      5576\n",
      "\n",
      "    accuracy                           0.85     25826\n",
      "   macro avg       0.78      0.75      0.77     25826\n",
      "weighted avg       0.84      0.85      0.85     25826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Matrice de confusion</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18722  1528]\n",
      " [ 2336  3240]]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"\"\"<h2><center>EFFET DES FONCTIONS D'ACTIVATION SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
    "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>\"\"\"))\n",
    "\n",
    "EPOCHS = 6\n",
    "BATCHS = 32\n",
    "\n",
    "UNITS1 = 25\n",
    "UNITS2 = 50\n",
    "UNITS3 = None\n",
    "UNITS4 = None\n",
    "UNITS5 = None\n",
    "UNITSOUT = 2\n",
    "\n",
    "ACTIV1 = \"tanh\"\n",
    "ACTIV2 = \"tanh\"\n",
    "ACTIV3 = None\n",
    "ACTIV4 = None\n",
    "ACTIV5 = None\n",
    "\n",
    "\n",
    "inputs = Input(shape = X_train_scaled.shape[1], name = \"Input\")\n",
    "dense1 = Dense(units = UNITS1, activation = ACTIV1, kernel_initializer = \"normal\", name = \"Dense_1\")\n",
    "dense2 = Dense(units = UNITS2, activation = ACTIV2, kernel_initializer = \"normal\", name = \"Dense_2\")\n",
    "dense3 = Dense(units = UNITSOUT, activation = \"softmax\", name = \"Dense_3\")\n",
    "\n",
    "x = dense1(inputs)\n",
    "x = dense2(x)\n",
    "outputs = dense3(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "training_history = model.fit(X_train_scaled, y_train, epochs = EPOCHS, batch_size = BATCHS, validation_data=(X_test_scaled,y_test))\n",
    "\n",
    "#calcul du score\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "#prédiction\n",
    "test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "y_test_class = y_test\n",
    "y_pred_class = np.argmax(test_pred, axis = 1)\n",
    "\n",
    "#Résultats\n",
    "precis = classification_report(y_test_class, y_pred_class,output_dict=True)\n",
    "\n",
    "#Output\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
    "Ce modèle avait 2 couches denses :\n",
    "<ul><li>la première avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la seconde avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
    "<li> apprentissage sur <b>{} epochs</b> par batch de <b>{}</b>.</li></ul>\n",
    "\"\"\".format(UNITS1, ACTIV1, UNITS2, ACTIV2, EPOCHS, BATCHS)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font>\n",
    "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>)</li>\n",
    "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>).\n",
    "<li>La précision globale du modèle est de <b>{} %</b>.</li></ul>\n",
    "L'activation des couches denses par la fonction tangente hyperbolique (au lieu de relu dans modèle initial) \n",
    "ne semble pas modifier les performances.\n",
    "\"\"\".format(\n",
    "    round(100*precis[\"1\"][\"precision\"],2),\n",
    "    round(100*precis[\"1\"][\"recall\"],2),\n",
    "    round(100*precis[\"0\"][\"precision\"],2),\n",
    "    round(100*precis[\"0\"][\"recall\"],2),\n",
    "    round(100*precis[\"accuracy\"],2)\n",
    ")))\n",
    "\n",
    "display(Markdown(\"<i><b>Rapport de classification</b></i>\"))\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "display(Markdown(\"<i><b>Matrice de confusion</b></i>\"))\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ad4f998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2><center>EFFET DU NOMBRE DE COUCHES DE NEURONES SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
       "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "3229/3229 [==============================] - 3s 950us/step - loss: 0.3540 - accuracy: 0.8463 - val_loss: 0.3423 - val_accuracy: 0.8531\n",
      "Epoch 2/6\n",
      "3229/3229 [==============================] - 3s 909us/step - loss: 0.3446 - accuracy: 0.8501 - val_loss: 0.3411 - val_accuracy: 0.8526\n",
      "Epoch 3/6\n",
      "3229/3229 [==============================] - 3s 907us/step - loss: 0.3421 - accuracy: 0.8503 - val_loss: 0.3365 - val_accuracy: 0.8551\n",
      "Epoch 4/6\n",
      "3229/3229 [==============================] - 3s 929us/step - loss: 0.3402 - accuracy: 0.8521 - val_loss: 0.3353 - val_accuracy: 0.8552\n",
      "Epoch 5/6\n",
      "3229/3229 [==============================] - 3s 917us/step - loss: 0.3386 - accuracy: 0.8527 - val_loss: 0.3373 - val_accuracy: 0.8560\n",
      "Epoch 6/6\n",
      "3229/3229 [==============================] - 3s 918us/step - loss: 0.3371 - accuracy: 0.8531 - val_loss: 0.3331 - val_accuracy: 0.8566\n",
      "808/808 [==============================] - 0s 594us/step - loss: 0.3331 - accuracy: 0.8566\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
       "Ce modèle avait 3 couches denses :\n",
       "<ul><li>la première avec <b>25 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la seconde avec <b>50 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la troisième avec <b>50 neurones</b> et une fonction d'activation <b>relu</b>.</li>\n",
       "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
       "<li> apprentissage sur <b>6 epochs</b> par batch de <b>32</b>.</li></ul>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 22)]              0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 25)                575       \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 50)                1300      \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " Dense_4 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,527\n",
      "Trainable params: 4,527\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font color = 'navy>\n",
       "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>74.43 %</b> (<i>recall = <b>51.15 %</b></i>)</li>\n",
       "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>87.61 %</b> (<i>recall = <b>95.16 %</b></i>).\n",
       "<li>La précision globale du modèle est de <b>85.66 %</b>.</li></ul>\n",
       "L'activation des couches denses par la fonction tangente hyperbolique (au lieu de relu dans modèle initial) \n",
       "ne semble pas modifier les performances.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Rapport de classification</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     20250\n",
      "           1       0.74      0.51      0.61      5576\n",
      "\n",
      "    accuracy                           0.86     25826\n",
      "   macro avg       0.81      0.73      0.76     25826\n",
      "weighted avg       0.85      0.86      0.85     25826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<i><b>Matrice de confusion</b></i>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19270   980]\n",
      " [ 2724  2852]]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"\"\"<h2><center>EFFET DU NOMBRE DE COUCHES DE NEURONES SUR LE MODÈLE DE DEEP LEARNING</h2></center>\n",
    "<h4><u><font color = 'navy'>Entrainement du modèle :</font><u></h4>\"\"\"))\n",
    "\n",
    "EPOCHS = 6\n",
    "BATCHS = 32\n",
    "\n",
    "UNITS1 = 25\n",
    "UNITS2 = 50\n",
    "UNITS3 = 50\n",
    "UNITS4 = None\n",
    "UNITS5 = None\n",
    "UNITSOUT = 2\n",
    "\n",
    "ACTIV1 = \"relu\"\n",
    "ACTIV2 = \"relu\"\n",
    "ACTIV3 = \"relu\"\n",
    "ACTIV4 = None\n",
    "ACTIV5 = None\n",
    "\n",
    "\n",
    "inputs = Input(shape = X_train_scaled.shape[1], name = \"Input\")\n",
    "dense1 = Dense(units = UNITS1, activation = ACTIV1, kernel_initializer = \"normal\", name = \"Dense_1\")\n",
    "dense2 = Dense(units = UNITS2, activation = ACTIV2, kernel_initializer = \"normal\", name = \"Dense_2\")\n",
    "dense3 = Dense(units = UNITS3, activation = ACTIV3, kernel_initializer = \"normal\", name = \"Dense_3\")\n",
    "dense4 = Dense(units = UNITSOUT, activation = \"softmax\", name = \"Dense_4\")\n",
    "\n",
    "x = dense1(inputs)\n",
    "x = dense2(x)\n",
    "x = dense3(x)\n",
    "outputs = dense4(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "training_history = model.fit(X_train_scaled, y_train, epochs = EPOCHS, batch_size = BATCHS, validation_data=(X_test_scaled,y_test))\n",
    "\n",
    "#calcul du score\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "#prédiction\n",
    "test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "y_test_class = y_test\n",
    "y_pred_class = np.argmax(test_pred, axis = 1)\n",
    "\n",
    "#Résultats\n",
    "precis = classification_report(y_test_class, y_pred_class,output_dict=True)\n",
    "\n",
    "#Output\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Récapitulatif du modèle :</h4></u></font>\n",
    "Ce modèle avait 3 couches denses :\n",
    "<ul><li>la première avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la seconde avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la troisième avec <b>{} neurones</b> et une fonction d'activation <b>{}</b>.</li>\n",
    "<li> la couche de sortie comportait <b>2 neurones</b> et une fonction d'activation <b>softmax</b>.</li>\n",
    "<li> apprentissage sur <b>{} epochs</b> par batch de <b>{}</b>.</li></ul>\n",
    "\"\"\".format(UNITS1, ACTIV1, UNITS2, ACTIV2, UNITS3, ACTIV3, EPOCHS, BATCHS)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "display(Markdown(\"\"\"<h4><u><font color = 'navy'>Résultats du modèle :</h4></u></font color = 'navy>\n",
    "<ul><li> Prédiction des <b>jours de pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>)</li>\n",
    "<li> Prédiction des <b>jours sans pluie</b> avec une précision de <b>{} %</b> (<i>recall = <b>{} %</b></i>).\n",
    "<li>La précision globale du modèle est de <b>{} %</b>.</li></ul>\n",
    "L'activation des couches denses par la fonction tangente hyperbolique (au lieu de relu dans modèle initial) \n",
    "ne semble pas modifier les performances.\n",
    "\"\"\".format(\n",
    "    round(100*precis[\"1\"][\"precision\"],2),\n",
    "    round(100*precis[\"1\"][\"recall\"],2),\n",
    "    round(100*precis[\"0\"][\"precision\"],2),\n",
    "    round(100*precis[\"0\"][\"recall\"],2),\n",
    "    round(100*precis[\"accuracy\"],2)\n",
    ")))\n",
    "\n",
    "display(Markdown(\"<i><b>Rapport de classification</b></i>\"))\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "display(Markdown(\"<i><b>Matrice de confusion</b></i>\"))\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
